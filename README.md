Modeling Neuronal Responses to Active and Passive Movements in the Visual Thalamus

Description
Neuroscience has long distinguished between sensory processes and the interpretation of those senses in the context of ongoing behavior, traditionally relegating vision to the former category. However, emerging evidence challenges this dichotomy, suggesting that neurons in the thalamus and cortex, previously considered pure sensory encoders, also integrate behavioral parameters such as pupil dilation, locomotion, and facial expressions. This project builds on these findings by focusing on how the visual thalamus responds to active and passive movements, integrating simultaneous 3D reconstructions of freely moving behavior with high-throughput neuronal recordings. Through computational analysis, we aim to model how visual circuitries are influenced by specific behavioral parameters, contributing to a more nuanced understanding of visual processing during natural behaviors.

Objectives
•	To investigate the encoding of active and passive movements by neurons in the visual thalamus.
•	To apply and compare different machine learning approaches, including Generalized Linear Models (GLM) and Extreme Gradient Boosting (XGB), for predicting neuronal activity based on ongoing movements.
•	To develop a quantitative model that elucidates how visual neuronal circuitries integrate sensory inputs with behavioral states.

Installation
To run this project, ensure you have the following Python libraries installed:
•	NumPy
•	Seaborn
•	pandas
•	matplotlib
•	pyglmnet
•	xgboost

Visualizations
The analysis generates insightful visualizations, including:
•	Scatter plots that illustrate the relationships among the variables.
•	Heatmaps that display the intensity of neuronal responses to different behavioral parameters.

Authors
•	Fangfei Lin


![image](https://github.com/Ginny-Bioinformatics/Modeling-Neuronal-Responses-to-Active-and-Passive-Movements-in-the-Visual-Thalamus/assets/160854085/fade8573-cec3-4023-9f16-6ae8a975dcb1)
